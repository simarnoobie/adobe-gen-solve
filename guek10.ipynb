{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 01:39:34,912 - INFO - Loading and preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, UpSampling2D, Input, concatenate, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import logging\n",
    "from scipy.interpolate import splprep, splev\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Paths\n",
    "train_folder = 'project_directory/train_folder'\n",
    "test_csv_file = 'project_directory/test_folder/test.csv'\n",
    "output_csv_file = 'output.csv'\n",
    "\n",
    "IMAGE_SIZE = (128, 128)\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def log_info(message):\n",
    "    logging.info(message)\n",
    "\n",
    "def load_images_from_folder(folder, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            for filename in os.listdir(label_folder):\n",
    "                img_path = os.path.join(label_folder, filename)\n",
    "                image = load_img(img_path, target_size=image_size, color_mode='rgb')\n",
    "                image = img_to_array(image)\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def preprocess_doodles(train_folder, test_csv_file, image_size):\n",
    "    X_train, y_train = load_images_from_folder(train_folder, image_size)\n",
    "    X_test, _ = preprocess_test_csv(test_csv_file, image_size)\n",
    "    validate_input_data(X_train, y_train)\n",
    "    return X_train, X_test, y_train, _\n",
    "\n",
    "def preprocess_test_csv(csv_file, image_size):\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    images = []\n",
    "    for _, row in df.iterrows():\n",
    "        bezier_points = np.array(row).reshape(-1, 2)\n",
    "        image = bezier_to_image(bezier_points, image_size)\n",
    "        images.append(image)\n",
    "    return np.array(images), None\n",
    "\n",
    "def bezier_to_image(bezier_points, image_size):\n",
    "    image = np.zeros(image_size, dtype=np.uint8)\n",
    "    for i in range(len(bezier_points) - 1):\n",
    "        pt1 = (int(bezier_points[i][0] * image_size[0]), int(bezier_points[i][1] * image_size[1]))\n",
    "        pt2 = (int(bezier_points[i + 1][0] * image_size[0]), int(bezier_points[i + 1][1] * image_size[1]))\n",
    "        cv2.line(image, pt1, pt2, 255, 1)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    return image\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_unet(input_size=(128, 128, 3)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    def conv_block(x, filters):\n",
    "        x = Conv2D(filters, 3, activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters, 3, activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    conv1 = conv_block(inputs, 64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = conv_block(pool1, 128)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = conv_block(pool2, 256)\n",
    "\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up4 = concatenate([up4, conv2])\n",
    "    conv4 = conv_block(up4, 128)\n",
    "\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up5 = concatenate([up5, conv1])\n",
    "    conv5 = conv_block(up5, 64)\n",
    "\n",
    "    outputs = Conv2D(3, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def create_masks(images, mask_percentage=0.2):\n",
    "    masks = np.ones_like(images)\n",
    "    for i in range(len(images)):\n",
    "        n_pixels = images[i].shape[0] * images[i].shape[1]\n",
    "        n_mask = int(n_pixels * mask_percentage)\n",
    "        mask_indices = np.random.choice(n_pixels, n_mask, replace=False)\n",
    "        masks[i].reshape(-1, 3)[mask_indices] = 0\n",
    "    return masks\n",
    "\n",
    "def train_model(model, images, labels):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "        shear_range=0.1,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    datagen.fit(images)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(datagen.flow(images, labels, batch_size=32), epochs=50, validation_split=0.1,\n",
    "              callbacks=[checkpoint, early_stop])\n",
    "\n",
    "def train_inpainting_model(images, epochs=50, batch_size=32):\n",
    "    model = build_unet(input_size=images.shape[1:])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        log_info(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        masks = create_masks(images)\n",
    "        masked_images = images * masks\n",
    "        model.fit(masked_images, images, batch_size=batch_size, epochs=1, verbose=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "def detect_symmetry(image, threshold=0.95):\n",
    "    gray = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    height, width = gray.shape\n",
    "    left = gray[:, :width//2]\n",
    "    right = cv2.flip(gray[:, width//2:], 1)\n",
    "    \n",
    "    similarity = np.sum(left == right) / (height * (width//2))\n",
    "    return similarity > threshold\n",
    "\n",
    "def detect_rotational_symmetry(image, threshold=0.95):\n",
    "    gray = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    height, width = gray.shape\n",
    "    rotated = cv2.rotate(gray, cv2.ROTATE_180)\n",
    "    similarity = np.sum(gray == rotated) / (height * width)\n",
    "    return similarity > threshold\n",
    "\n",
    "def apply_symmetry(image):\n",
    "    height, width, _ = image.shape\n",
    "    left_half = image[:, :width//2]\n",
    "    symmetrical_image = np.concatenate((left_half, cv2.flip(left_half, 1)), axis=1)\n",
    "    return symmetrical_image\n",
    "\n",
    "def complete_incomplete_curves(images, model):\n",
    "    completed_images = []\n",
    "    for image in images:\n",
    "        is_symmetric = detect_symmetry(image)\n",
    "        is_rotational_symmetric = detect_rotational_symmetry(image)\n",
    "\n",
    "        mask = np.all(image == [255, 255, 255], axis=-1).astype(np.float32)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        mask = np.repeat(mask, 3, axis=-1)\n",
    "\n",
    "        masked_image = image * (1 - mask)\n",
    "        completed = model.predict(np.expand_dims(masked_image, 0))[0]\n",
    "        result = image * (1 - mask) + completed * mask\n",
    "        \n",
    "        if is_symmetric:\n",
    "            result = apply_symmetry(result)\n",
    "        \n",
    "        if is_rotational_symmetric:\n",
    "            result = apply_symmetry(cv2.rotate(result, cv2.ROTATE_180))\n",
    "        \n",
    "        completed_images.append(result)\n",
    "\n",
    "    return np.array(completed_images)\n",
    "\n",
    "def save_bezier_coordinates_to_csv(bezier_coordinates, output_csv_file):\n",
    "    df = pd.DataFrame(bezier_coordinates)\n",
    "    df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "def process_curve_points(points, method='spline'):\n",
    "    if method == 'spline':\n",
    "        tck, _ = splprep(points.T, s=0)\n",
    "        new_points = splev(np.linspace(0, 1, 100), tck)\n",
    "        return np.array(new_points).T\n",
    "    elif method == 'polynomial':\n",
    "        coeffs = np.polyfit(points[:, 0], points[:, 1], deg=3)\n",
    "        poly = np.poly1d(coeffs)\n",
    "        return np.vstack([points[:, 0], poly(points[:, 0])]).T\n",
    "    elif method == 'fourier':\n",
    "        # Implement Fourier transform based regularization\n",
    "        pass\n",
    "    else:\n",
    "        return points  # Default to no regularization\n",
    "\n",
    "def simplify_curve(points, tolerance=0.01):\n",
    "    line = LineString(points)\n",
    "    simplified = line.simplify(tolerance, preserve_topology=True)\n",
    "    return np.array(simplified)\n",
    "\n",
    "def validate_input_data(images, labels):\n",
    "    if images.shape[0] != labels.shape[0]:\n",
    "        raise ValueError(\"Number of images does not match number of labels.\")\n",
    "    if images.shape[1:] != (128, 128, 3):\n",
    "        raise ValueError(f\"Image shape {images.shape[1:]} is not as expected (128, 128, 3).\")\n",
    "    if labels.ndim != 1:\n",
    "        raise ValueError(\"Labels should be a 1D array.\")\n",
    "\n",
    "def plot_curves(original, processed, title='Curve'):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(original[:, 0], original[:, 1], label='Original', linestyle='--', color='gray')\n",
    "    plt.plot(processed[:, 0], processed[:, 1], label='Processed', color='blue')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def detect_edges(image):\n",
    "    gray = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    points = np.argwhere(edges > 0)\n",
    "    return points\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predicted_labels))\n",
    "\n",
    "def main():\n",
    "    log_info(\"Loading and preprocessing data...\")\n",
    "    X_train, X_test, y_train, y_test = preprocess_doodles(train_folder, test_csv_file, IMAGE_SIZE)\n",
    "\n",
    "    log_info(\"Building and training model...\")\n",
    "    model = build_model(X_train.shape[1:], NUM_CLASSES)\n",
    "    train_model(model, X_train, y_train)\n",
    "\n",
    "    log_info(\"Training inpainting model...\")\n",
    "    inpainting_model = train_inpainting_model(X_train)\n",
    "\n",
    "    log_info(\"Completing incomplete curves...\")\n",
    "    completed_images = complete_incomplete_curves(X_test, inpainting_model)\n",
    "\n",
    "    log_info(\"Processing curves...\")\n",
    "    bezier_coordinates = []\n",
    "    for image in completed_images:\n",
    "        points = detect_edges(image)\n",
    "        points = process_curve_points(points, method='spline')\n",
    "        points = simplify_curve(points)\n",
    "        bezier_coordinates.append(points.flatten())\n",
    "\n",
    "    log_info(\"Saving bezier coordinates...\")\n",
    "    save_bezier_coordinates_to_csv(bezier_coordinates, output_csv_file)\n",
    "\n",
    "    log_info(\"Evaluating model...\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
